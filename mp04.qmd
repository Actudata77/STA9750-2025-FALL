---
title: "Mini-Project #04 - Just the Fact(-Check)s!"
author: "Hyacinthe Sarr"
editor:
    mode: source
format:
  html:
    toc: true
    toc-location: body
    toc-title: "Contents"
    number-sections: false
    theme: zephyr
    css: styles.css
    code-fold: true
    code-summary: "Show code"
    mainfont: Georgia
    embed-resources: true
execute:
  warning: false
  message: false
---

![](images/jobsreport.png){width="85%" fig-align="center"}

## Introduction

The monthly jobs report released by the Bureau of Labor Statistics (BLS) plays an outsized role in shaping public narratives about the American economy. Beyond its impact on financial markets and policy decisions, the employment number, formally the Current Employment Statistics (CES) estimate of total nonfarm payroll, is increasingly used in political debates. In August 2025, the sudden dismissal of BLS Commissioner Dr. Erika McEntarfer intensified national scrutiny of the accuracy and reliability of CES estimates, especially the month-to-month revisions.

This mini-project investigates whether recent CES revisions are unusually large or politically concerning. To answer this question, I use modern data-acquisition techniques (`httr2`, `rvest`), multi-table data processing (`dplyr`), visualization (`ggplot2`), and statistical inference (`infer`) to construct a reproducible analysis pipeline. By re-creating the BLS‚Äôs reported CES levels and revisions directly from the agency‚Äôs website, I can explore long-run revision patterns and evaluate some factual claims.

## Data Acquisition and Preparation

To evaluate claims about **CES** accuracy, I first need two foundational datasets:

- **Final CES employment levels** ‚Äì the seasonally adjusted **total nonfarm payroll** series that provides the headline jobs number reported each month by the **BLS**.
- **Cycle-to-cycle CES revisions** ‚Äì tables that track how the first estimate of **total nonfarm payroll** is updated in subsequent releases, allowing us to quantify the size and direction of **revisions** over time.

### Task 1: Download CES Total Nonfarm Payroll

To obtain a complete historical dataset from January 1979 through June 2025, we need a custom HTTP POST request using `httr2` that mirrors the exact request sent by the **BLS** website. After downloading the resulting HTML page, I use `rvest` to extract and tidy the main table into a clean, two-column dataset of dates and employment levels in **total nonfarm payroll**.


```{r}
## Task 1 ‚Äî Download CES Total Nonfarm Payroll

#| label: ces-final
#| message: false
#| warning: false

library(httr2)
library(rvest)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(readr)
library(purrr)
library(DT)

# A helper function for pretty interactive tables
nice_table <- function(x, caption = NULL, page_len = 10) {
  datatable(
    x,
    caption = caption,
    options = list(
      pageLength = page_len,
      scrollX    = TRUE,
      dom        = "tip"
    )
  )
}

tiny_table <- function(df, caption = "") {
  df |>
    datatable(
      caption = htmltools::tags$caption(
        style = "caption-side: top; text-align: center; font-weight: bold;",
        caption
      ),
      options = list(
        paging = FALSE,
        scrollX = FALSE,
        autoWidth = TRUE,
        dom = "t",
        columnDefs = list(
          list(width = "120px", targets = "_all")
        )
      )
    )
}

# 1. Build POST request exactly like BLS Toppicks form
ces_req <- request("https://data.bls.gov/pdq/SurveyOutputServlet") |>
  req_user_agent("STA9750 student (Baruch) - hyacinthe.sarr@baruchmail.cuny.edu") |>
  req_headers(Referer = "https://data.bls.gov/toppicks?survey=ce") |>
  req_body_form(
    request_action    = "get_data",
    reformat          = "true",
    from_results_page = "true",
    from_year         = "1979",
    to_year           = "2025",
    "Go.x"            = "12",
    "Go.y"            = "10",
    initial_request   = "false",
    data_tool         = "surveymost",
    series_id         = "CES0000000001",
    years_option      = "specific_years"
  )

# 2. Perform request + parse HTML
ces_resp <- ces_req |> req_perform()
ces_page <- ces_resp |> resp_body_html()

# 3. Extract all tables from the page
ces_tbl_list <- ces_page |>
  html_elements("table") |>
  html_table()

# The table we want is the 2nd one
ces_tbl_raw <- ces_tbl_list[[2]]

# 4. Clean into tidy (date, level) format
ces_levels <- ces_tbl_raw |>
  select(Year, Jan:Dec) |>
  pivot_longer(
    cols      = -Year,
    names_to  = "Month",
    values_to = "Level_raw"
  ) |>
  mutate(
    Level      = parse_number(Level_raw),
    Month      = str_to_title(Month), # Capitalize first letter
    Month3     = str_sub(Month, 1, 3),
    Date       = ym(str_c(Year, " ", Month3))
  ) |>
  select(Date, Level) |>
  drop_na(Date, Level) |>
  arrange(Date) |>
  filter(
    Date >= as.Date("1979-01-01"),
    Date <= as.Date("2025-06-01")
  )

# Raw CES scraped table (first 8 rows only)
nice_table(head(ces_tbl_raw, 8),
  caption = "Raw CES Table (First 8 Rows Only)"
)

# Cleaned CES levels ‚Äî head
nice_table(head(ces_levels, 6),
  caption = "Cleaned CES Levels ‚Äî First 6 Rows"
)
```

### Task 2: CES Revisions Tables 

While **CES levels** indicate the headline jobs number, **revisions** reveal how initial estimates are adjusted as more complete survey responses become available. The magnitude and direction of these **revisions** are central to the public debate surrounding the accuracy of **BLS** reporting.

Unlike Task 1, the revisions page contains dozens of year-by-year tables within a static HTML page. Accessing and processing these tables requires:

- A correctly authenticated request using custom headers.
- Extracting **all** HTML tables using `rvest` and identifying which ones correspond to 1979‚Äì2025  
- Writing a function to standardize each year‚Äôs table into `date`, `original`, `final`, and `revision` columns  
- Combining all years into one long dataset suitable for time-series analysis.

```{r}
#| label: ces-revisions
#| message: false
#| warning: false

library(httr2)
library(rvest)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(readr)
library(purrr)

# 1. Request the revisions page (avoid 403 with UA + Referer)
rev_req <- request("https://www.bls.gov/web/empsit/cesnaicsrev.htm") |>
  req_user_agent("STA9750 student (Baruch) - hyacinthe.sarr@baruchmail.cuny.edu") |>
  req_headers(Referer = "https://www.bls.gov/web/empsit/")

rev_resp <- rev_req |> req_perform()
rev_page <- rev_resp |> resp_body_html()

# 2. All tables on the page
rev_tbl_list <- rev_page |>
  html_elements("table") |>
  html_table(header = FALSE)

# 3. Find which table block contains 1979 in the 2nd column
year_table_candidates <- which(
  vapply(
    rev_tbl_list,
    function(tbl) {
      ncol(tbl) >= 2 &&
        any(grepl("1979", as.character(tbl[[2]])))
    },
    logical(1)
  )
)

# Use the first match as the start of the year-by-year block
year_table_index <- min(year_table_candidates)

# The revisions page has one table per year, in order.
# Take 47 consecutive tables: 1979‚Äì2025.
revision_tables <- rev_tbl_list[seq(from = year_table_index, length.out = 47)]

# 4. Function to extract one table into (date, original, final, revision)
extract_revisions_from_tbl <- function(tbl) {
  tbl |>
    # pick the columns we care about, by POSITION
    select(
      month    = 1, # "Jan.", "Feb.", ...
      year_col = 2, # 1979, 1980, ...
      original = 3, # 1st estimate, SA
      final    = 5 # 3rd estimate, SA
    ) |>
    # keep only rows where year_col is a 4-digit year
    filter(str_detect(year_col, "^[0-9]{4}$")) |>
    # take the 12 months
    slice(1:12) |>
    mutate(
      month    = str_sub(month, 1, 3),
      date     = ym(str_c(year_col, " ", month)),
      original = parse_number(original),
      final    = parse_number(final),
      revision = final - original
    ) |>
    select(date, original, final, revision) |>
    drop_na(date) |>
    arrange(date)
}

# 5. Apply to all revision tables and bind rows
ces_revisions <- map_dfr(revision_tables, extract_revisions_from_tbl) |>
  filter(
    date >= as.Date("1979-01-01"),
    date <= as.Date("2025-06-01")
  ) |>
  arrange(date)
```



```{r}
# Make sure the data we JOIN on use lowercase 'date'
if ("Date" %in% names(ces_levels)) {
  ces_levels <- ces_levels |>
    rename(date = Date)
}

if ("Date" %in% names(ces_revisions)) {
  ces_revisions <- ces_revisions |>
    rename(date = Date)
}

# Combining tables into final CES dataset
ces <- left_join(ces_levels, ces_revisions, by = "date")

# Nice DT table for revisions (title-case just for display)
nice_table(
  ces_revisions |>
    rename_with(stringr::str_to_title), # Date, Original, Final, Revision
  caption = "CES Revisions (Original vs Final Estimates), 1979‚Äì2025",
  page_len = 12
)
```

We now have a complete dataset covering more than 45 years of employment reporting. By joining the two sources into a single `ces` table, I can explore:

- How total nonfarm payroll has evolved over time  
- How frequently and how severely initial CES estimates are revised  
- Whether the size and direction of revisions display meaningful patterns across decades, months, or political eras. 

## Data Integration and Exploration

### Task 3: Data Exploration and Visualization

With both the final **CES** employment levels and the month-to-month **revisions** in hand, I now explore how these series behave over the 1979‚Äì2025 window. In this section I:

- compute several summary statistics about the size and direction of revisions; and  
- construct multiple visualizations of both the employment level and revision patterns.

These results will later support my statistical analysis and final fact-check.

```{r}
#| label: ces-theme-setup
#| message: false
#| warning: false

# Custom palette for MP04
MP04_pal <- list(
  blue_main      = "#4A90E2", # soft professional blue
  blue_dark      = "#2F5CA8", # stronger blue
  red_revision   = "#C0392B", # rich crimson
  red_soft       = "#D95F02", # reddish-orange
  gray_baseline  = "#7F8C8D", # neutral gray
  gray_light     = "#D0D3D4", # light gray
  highlight_gold = "#DAA520" # gold highlight
)

theme_mini04 <- function(base_size = 12) {
  theme_minimal(base_size = base_size) +
    theme(
      plot.title       = element_text(face = "bold", size = base_size + 2),
      plot.subtitle    = element_text(size = base_size),
      axis.title       = element_text(face = "bold"),
      axis.text        = element_text(color = "gray20"),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "#ECECEC"),
      plot.background  = element_rect(fill = "white", color = NA),
      panel.background = element_rect(fill = "white", color = NA)
    )
}
```

```{r}
#| label: ces-eda-setup
#| message: false
#| warning: false

library(dplyr)
library(lubridate)

# 1. Rebuild the full CES table (just in case it was modified above)
ces <- left_join(ces_levels, ces_revisions, by = "date")

# 2. Make sure column names are in lower-case for coding
#    (handles cases where we renamed them to Title Case for DT display)
ces <- ces |>
  rename_with(tolower)
# After this we should have: date, level, original, final, revision

# 3. Add helper variables for EDA
ces_eda <- ces |>
  mutate(
    year = year(date),
    month = month(date, label = TRUE, abbr = TRUE),
    decade = floor(year / 10) * 10,
    abs_revision = abs(revision),
    revision_pct_level = revision / level,
    abs_revision_pct_level = abs(revision) / level
  )
```

## Summary statistics

```{r}
#| label: ces-summary-stats
#| message: false
#| warning: false

# 1. Largest positive/negative
largest_pos <- ces_eda |> slice_max(revision, n = 1)
largest_neg <- ces_eda |> slice_min(revision, n = 1)

# 2. Overall stats (raw)
overall_stats <- ces_eda |>
  summarise(
    mean_revision = mean(revision, na.rm = TRUE),
    mean_abs_revision = mean(abs_revision, na.rm = TRUE),
    mean_abs_revision_pct_level = mean(abs_revision_pct_level, na.rm = TRUE),
    share_positive = mean(revision > 0, na.rm = TRUE)
  )

# 3. By decade (raw)
positive_by_decade <- ces_eda |>
  group_by(decade) |>
  summarise(
    n = n(),
    frac_positive = mean(revision > 0, na.rm = TRUE),
    mean_abs_rev = mean(abs_revision, na.rm = TRUE),
    .groups = "drop"
  )

# Month-level pattern (raw summary)
month_pattern <- ces_eda |>
  group_by(month) |>
  summarise(
    mean_abs_rev = mean(abs_revision, na.rm = TRUE),
    mean_abs_rev_pct_level = mean(abs_revision_pct_level, na.rm = TRUE),
    .groups = "drop"
  )

# Pretty month table for display
month_display <- month_pattern |>
  transmute(
    Month = month,
    `Mean |Revision|` = round(mean_abs_rev, 1),
    `Mean |Revision| / Level` = round(mean_abs_rev_pct_level, 4)
  )

# ===================================================================
#                  DISPLAY TABLES (PRETTY + ROUNDED)
# ===================================================================

# ----  A. Compact 1-row tables (unchanged) ----
tiny_table(
  largest_pos |> rename_with(stringr::str_to_title),
  caption = "Largest Positive CES Revision (1979‚Äì2025)"
)

tiny_table(
  largest_neg |> rename_with(stringr::str_to_title),
  caption = "Largest Negative CES Revision (1979‚Äì2025)"
)


# ----  B. PRETTY DISPLAY VERSIONS FOR LARGE TABLES ----

# 1. Overall stats table (rounded + nice column names)
overall_display <- overall_stats |>
  mutate(
    mean_revision               = round(mean_revision, 1),
    mean_abs_revision           = round(mean_abs_revision, 1),
    mean_abs_revision_pct_level = round(mean_abs_revision_pct_level, 4),
    share_positive              = round(share_positive, 2)
  ) |>
  rename(
    `Mean Revision`            = mean_revision,
    `Mean |Revision|`          = mean_abs_revision,
    `Mean |Revision| / Level`  = mean_abs_revision_pct_level,
    `Share Positive`           = share_positive
  )


# 2. Decade table (rounded + nice names)
decade_display <- positive_by_decade |>
  mutate(
    frac_positive = round(frac_positive, 2),
    mean_abs_rev  = round(mean_abs_rev, 1)
  ) |>
  rename(
    Decade = decade,
    `Number of Months` = n,
    `Fraction Positive` = frac_positive,
    `Mean |Revision|` = mean_abs_rev
  )


# 3. Month table (rounded + nice names)
month_display <- month_pattern |>
  mutate(
    mean_abs_rev           = round(mean_abs_rev, 1),
    mean_abs_rev_pct_level = round(mean_abs_rev_pct_level, 4)
  ) |>
  rename(
    Month = month,
    `Mean |Revision|` = mean_abs_rev,
    `Mean |Revision| / Level` = mean_abs_rev_pct_level
  )


# ----  C. Display pretty tables ----

nice_table(
  overall_display,
  caption = "Overall Summary of CES Revisions, 1979‚Äì2025",
  page_len = 5
)

nice_table(
  decade_display,
  caption = "CES Revision Patterns by Decade",
  page_len = 10
)

nice_table(
  month_display,
  caption = "Average Absolute CES Revision by Calendar Month",
  page_len = 12
)
```

From this, we can easily pull **6 or more statistics** to use, for example:

- date & size of the largest positive and negative revisions;  
- mean revision and mean absolute revision (thousands of jobs);  
- average absolute revision as a percent of the employment level;
- share of revisions that are positive overall;  
- share positive & mean revision by decade;  
- which months have systematically larger revision (in absolute value).

### Visualizations

### Plot 1 ‚Äì Employment level over time

```{r employment-level-time-series}
### Plot 1 ‚Äî Employment level over time
#| label: plot-level-ts
#| message: false
#| warning: false

library(ggplot2) # ‚Üê ADD THIS LINE

ggplot(ces_eda, aes(x = date, y = level)) +
  geom_line(color = MP04_pal$blue_main, linewidth = 0.8) +
  labs(
    title = "Total Nonfarm Payroll Employment, 1979‚Äì2025",
    x = "Year", y = "Employment (thousands)"
  ) +
  theme_mini04()
```

Employment in the United States rises steadily from the early 1980s through 2020, with noticeable dips during the early-1990s recession, the 2001 dot-com downturn, and the Great Recession of 2008‚Äì2009. The employment collapse in early 2020 (COVID-19 shock) is historically unprecedented, followed by the strongest rehiring surge in CES history. By 2024‚Äì2025, payroll employment reaches new record highs above 158 million.

### Plot 2 ‚Äì Revision time series

```{r revision-time-series}
### Plot 2 ‚Äî Revisions over time
#| label: plot-revision-ts
#| message: false
#| warning: false

ggplot(ces_eda, aes(x = date, y = revision)) +
  geom_hline(
    yintercept = 0, color = MP04_pal$gray_baseline,
    linetype = "dashed", linewidth = 0.6
  ) +
  geom_line(color = MP04_pal$red_revision, alpha = 0.7, linewidth = 0.6) +
  labs(
    title = "CES Revisions to Monthly Employment Change",
    x = "Year", y = "Revision (thousands)"
  ) +
  theme_mini04()
```

CES revisions fluctuate around zero, as expected for an unbiased estimation process. However, some periods exhibit unusually large corrections, particularly during recessions and major turning points. The 2020 COVID-19 year shows extreme revision spikes (upward and downward), reflecting unusually noisy labor market conditions. Outside of crisis years, typical revisions fall within ¬±50k workers.

### Plot 3 ‚Äì Distribution of revisions by decade

```{r revision-by-decade}
### Plot 3 ‚Äî Revisions by decade
#| label: plot-revision-decade
#| message: false
#| warning: false

ggplot(ces_eda, aes(x = factor(decade), y = revision)) +
  geom_hline(
    yintercept = 0, color = MP04_pal$gray_baseline,
    linetype = "dashed"
  ) +
  geom_boxplot(fill = MP04_pal$blue_dark, outlier.alpha = 0.4) +
  labs(
    title = "Distribution of CES Revisions by Decade",
    x = "Decade", y = "Revision (thousands)"
  ) +
  theme_mini04()
```

Each decade shows a tight concentration of revisions around zero, although outliers appear in every period. The 2020s exhibit the largest dispersion, driven by pandemic-era volatility. Earlier decades (1980s‚Äì2000s) show more stable and narrower revision ranges, consistent with more predictable labor market patterns.

### Plot 4 ‚Äì Average absolute revision by calendar month

This answers the question:‚ÄúAre there months that systematically have larger or smaller revisions?‚Äù

```{r average-absolute-revision-by-month}
### Plot 4 ‚Äî Average absolute revision by calendar month
#| label: plot-revision-month
#| message: false
#| warning: false

ggplot(month_pattern, aes(x = month, y = mean_abs_rev)) +
  geom_col(fill = MP04_pal$blue_main) +
  labs(
    title = "Average Absolute CES Revision by Calendar Month",
    x = "Month", y = "Average |revision| (thousands)"
  ) +
  theme_mini04()
```

Revisions show meaningful seasonal variation. March, April, and September display the largest average absolute revisions, suggesting that early-spring benchmark adjustments and late-summer seasonal transitions introduce additional uncertainty. February tends to have the smallest revisions, indicating more stable estimation conditions.

## Statistical Analysis

### Task 4: Statistical Inference

**1. Has the fraction of negative revisions increased post-2000?**

In this section I test whether **negative CES revisions** have become **more common after 2000**.  
Each month‚Äôs revision can be classified as either:

- **Negative** ‚Äì the final estimate is *lower* than the original estimate  
- **Non-negative** ‚Äì the final estimate is the same or higher  

I compare the **proportion of negative revisions** before 2000 to the proportion after 2000 using a
two-sample test for proportions (`prop_test()` from the **infer** package).
The null hypothesis is that the fractions are the same in both periods, while the alternative is that
negative revisions are **more frequent post-2000**.

```{r}
#| label: neg-revisions-post2000
#| message: false
#| warning: false

library(infer)
library(dplyr)
library(stringr)

# --------------------------------------------------
# 1. Prepare data: classify negative revisions + period
# --------------------------------------------------
ces_infer <- ces |>
  mutate(
    neg    = revision < 0,
    period = if_else(date < as.Date("2000-01-01"), "pre2000", "post2000")
  )

# --------------------------------------------------
# 2. Summary counts by period
# --------------------------------------------------
neg_counts <- ces_infer |>
  group_by(period) |>
  summarise(
    neg = sum(neg),
    n = n(),
    .groups = "drop"
  )

neg_counts_display <- neg_counts |>
  mutate(
    Period = str_to_title(period), # "Pre2000" -> "Pre2000" (already nice)
    `Negative Revisions` = neg,
    `Total Months` = n,
    `Proportion Negative` = round(neg / n, 3)
  ) |>
  select(
    Period,
    `Negative Revisions`,
    `Total Months`,
    `Proportion Negative`
  )

# --------------------------------------------------
# 3. Two-sample proportion test (Post-2000 > Pre-2000)
# --------------------------------------------------
neg_prop_test <- prop.test(
  x = c(
    neg_counts$neg[neg_counts$period == "pre2000"],
    neg_counts$neg[neg_counts$period == "post2000"]
  ),
  n = c(
    neg_counts$n[neg_counts$period == "pre2000"],
    neg_counts$n[neg_counts$period == "post2000"]
  ),
  alternative = "greater"
)

# Tidy test output
ci_vec <- neg_prop_test$conf.int # CI for (post - pre)
p_val <- neg_prop_test$p.value

test_display <- tibble(
  Test = "Two-sample proportion test (Post-2000 > Pre-2000)",
  `X-squared` = unname(neg_prop_test$statistic),
  df = unname(neg_prop_test$parameter),
  `p-value` = p_val,
  `95% CI (Post - Pre) Lower` = ci_vec[1],
  `95% CI (Post - Pre) Upper` = ci_vec[2],
  Sig = case_when(
    p_val < 0.001 ~ "***",
    p_val < 0.01 ~ "**",
    p_val < 0.05 ~ "*",
    TRUE ~ ""
  )
) |>
  mutate(
    `X-squared`                 = round(`X-squared`, 3),
    `p-value`                   = round(`p-value`, 3),
    `95% CI (Post - Pre) Lower` = round(`95% CI (Post - Pre) Lower`, 3),
    `95% CI (Post - Pre) Upper` = round(`95% CI (Post - Pre) Upper`, 3)
  )

# --------------------------------------------------
# 4. Display tables nicely
# --------------------------------------------------

# 4a. Negative revision rates by period
neg_counts_dt <- nice_table(
  neg_counts_display,
  caption  = "Negative CES Revisions by Period (Pre-2000 vs Post-2000)",
  page_len = 5
) |>
  DT::formatStyle(
    "Proportion Negative",
    background = DT::styleColorBar(
      range(neg_counts_display$`Proportion Negative`),
      "#cfe8ff"
    ),
    backgroundSize = "100% 80%",
    backgroundRepeat = "no-repeat",
    backgroundPosition = "center"
  )

neg_counts_dt

# 4b. Test summary with highlighted p-value and CI
test_dt <- nice_table(
  test_display,
  caption  = "Two-Sample Test for Increase in Negative Revision Rate Post-2000",
  page_len = 5
) |>
  DT::formatStyle(
    "p-value",
    fontWeight = DT::styleInterval(0.05, c("bold", "normal")),
    color      = DT::styleInterval(0.05, c("#b22222", "black"))
  )

test_dt
```

**2. Has the fraction of revisions of more than 1% increased post-2020?**

In this part of the project, we investigate whether the proportion of very large CES revisions (defined as revisions with absolute size ‚â• 1% of that month‚Äôs employment level) has increased in the post-2020 period.

```{r}
#| label: test-large-revisions
#| message: false
#| warning: false

library(infer)
library(dplyr)
library(stringr)

# -------------------------------
# 1. Prepare data
# -------------------------------
ces_infer2 <- ces |>
  mutate(
    large   = abs(revision) > 0.01 * level,
    period2 = if_else(date < as.Date("2020-01-01"), "pre2020", "post2020")
  )

# -------------------------------
# 2. Count large revisions by period
# -------------------------------
large_props <- ces_infer2 |>
  group_by(period2) |>
  summarise(
    n_large = sum(large),
    n_total = n(),
    prop_large = n_large / n_total,
    .groups = "drop"
  ) |>
  # Clean up column names & round values
  mutate(
    Period = str_to_title(period2),
    `Number of Large Revisions` = n_large,
    `Total Months` = n_total,
    `Proportion Large` = round(prop_large, 3)
  ) |>
  select(
    Period,
    `Number of Large Revisions`,
    `Total Months`,
    `Proportion Large`
  )

# -------------------------------
# 3. Display as a nice table
# -------------------------------
nice_table(
  large_props,
  caption = "Proportion of Large CES Revisions (More Than 1%), Pre- vs Post-2020",
  page_len = 5
)
```

This means CES revisions almost never reach even 1% of the monthly employment level, before or after 2020.

**3. Is the average revision significantly different from zero?**

```{r}
#| label: ces-test-mean-revision
#| message: false
#| warning: false

library(infer)
library(dplyr)
library(stringr)

# ============================================================
# 1. One-sample t-test: is the mean revision different from 0?
# ============================================================

# t-statistic from infer
t_test_rev <- ces |>
  specify(response = revision) |>
  hypothesize(null = "point", mu = 0) |>
  calculate(stat = "t")

t_stat <- t_test_rev$stat
df_val <- nrow(ces) - 1

# two-sided p-value for H0: mean = 0 vs HA: mean != 0
p_val <- 2 * pt(abs(t_stat), df = df_val, lower.tail = FALSE)

# ============================================================
# 2. Bootstrap 95% confidence interval for the mean revision
# ============================================================

set.seed(123)

t_test_rev_ci <- ces |>
  specify(response = revision) |>
  hypothesize(null = "point", mu = 0) |>
  generate(reps = 2000, type = "bootstrap") |>
  calculate(stat = "mean") |>
  get_confidence_interval(level = 0.95, type = "percentile")

ci_low <- t_test_rev_ci$lower_ci
ci_high <- t_test_rev_ci$upper_ci

# ============================================================
# 3. Sample mean + significance stars
# ============================================================

mean_rev <- mean(ces$revision)

sig_code <- case_when(
  p_val < 0.001 ~ "***",
  p_val < 0.01 ~ "**",
  p_val < 0.05 ~ "*",
  p_val < 0.1 ~ ".",
  TRUE ~ ""
)

mean_test_tbl <- tibble::tibble(
  `Mean Revision` = round(mean_rev, 3),
  `t-Statistic`   = round(t_stat, 3),
  df              = df_val,
  `p-value`       = signif(p_val, 3),
  `Lower 95% CI`  = round(ci_low, 3),
  `Upper 95% CI`  = round(ci_high, 3),
  Sig             = sig_code
)

# ============================================================
# 4. Display a single, compact table
# ============================================================

nice_table(
  mean_test_tbl,
  caption = "Test of Whether the Average CES Revision Differs from Zero (1979‚Äì2025)",
  page_len = 5
)
```
The average CES revision is approximately +11.5 thousand jobs.
A one-sample t-test finds this mean significantly greater than zero (t = 3.26, p ‚âà 0.001).
A percentile bootstrap CI is slightly wider and includes zero, reflecting skew in the revision distribution.
Overall, the evidence suggests that CES revisions tend to be modestly positive on average.

**4. Has the average revision increased post-2020?**

```{r}
### Task 4.4 ‚Äì Has the average revision increased post-2020?
# We test whether mean revisions are larger in the post-2020 period.


#| label: ces-mean-revision-post2020
#| message: false
#| warning: false

library(dplyr)
library(infer)
library(stringr)

# ---------------------------------------------------------------
# 1. Define pre/post-2020 periods and compute mean revisions
# ---------------------------------------------------------------
ces_infer3 <- ces |>
  mutate(
    period3 = if_else(date < as.Date("2020-01-01"), "pre2020", "post2020")
  )

rev_means <- ces_infer3 |>
  group_by(period3) |>
  summarise(
    mean_revision = mean(revision),
    n = n(),
    .groups = "drop"
  )

# Nicely formatted table of means by period
rev_means_display <- rev_means |>
  mutate(
    Period          = if_else(period3 == "pre2020", "Pre-2020", "Post-2020"),
    `Mean Revision` = round(mean_revision, 2),
    `Total Months`  = n
  ) |>
  select(Period, `Mean Revision`, `Total Months`)

# ---------------------------------------------------------------
# 2. Classical two-sample t-test (Post-2020 vs Pre-2020)
#    H0: mean_post - mean_pre = 0
#    H1: mean_post - mean_pre > 0 (average revision increased)
# ---------------------------------------------------------------
t_test_post2020 <- t.test(
  revision ~ period3,
  data        = ces_infer3,
  alternative = "greater"
)

mean_pre <- rev_means$mean_revision[rev_means$period3 == "pre2020"]
mean_post <- rev_means$mean_revision[rev_means$period3 == "post2020"]
diff_post_pre <- mean_post - mean_pre

# ---------------------------------------------------------------
# 3. Bootstrap CI for difference in means (Post - Pre) via infer
# ---------------------------------------------------------------
set.seed(123)

rev_ci_boot <- ces_infer3 |>
  specify(revision ~ period3) |>
  hypothesize(null = "independence") |>
  generate(reps = 2000, type = "bootstrap") |>
  calculate(
    stat = "diff in means",
    order = c("post2020", "pre2020")
  ) |>
  get_confidence_interval(level = 0.95, type = "percentile")

# ---------------------------------------------------------------
# 4. Compact test summary table
# ---------------------------------------------------------------
p_val <- t_test_post2020$p.value

rev_post2020_summary <- tibble::tibble(
  `Mean Revision (Pre-2020)` = round(mean_pre, 2),
  `Mean Revision (Post-2020)` = round(mean_post, 2),
  `Difference (Post - Pre)` = round(diff_post_pre, 2),
  `t-Statistic` = round(unname(t_test_post2020$statistic), 3),
  df = round(unname(t_test_post2020$parameter), 1),
  `p-value` = signif(p_val, 3),
  `95% CI (Post - Pre) Lower` = round(rev_ci_boot$lower_ci, 2),
  `95% CI (Post - Pre) Upper` = round(rev_ci_boot$upper_ci, 2),
  Sig = dplyr::case_when(
    p_val < 0.001 ~ "***",
    p_val < 0.01 ~ "**",
    p_val < 0.05 ~ "*",
    TRUE ~ ""
  )
)

# ---------------------------------------------------------------
# 5. Display nicely
# ---------------------------------------------------------------

nice_table(
  rev_means_display,
  caption = "Average CES Revision by Period (Pre- vs Post-2020)",
  page_len = 5
)

nice_table(
  rev_post2020_summary,
  caption = "Test of Whether the Average CES Revision Increased Post-2020",
  page_len = 5
)
```

There is no statistical evidence that average CES revisions increased post-2020.
The mean revision actually decreased slightly (from ~13k to ~0.5k), but the difference is not statistically significant
(t statictic = ‚Äì0.70, p-value = 0.76, CI: ‚Äì49k to 21k).

**5. Are revisions larger when the underlying change in CES level is larger?**

```{r}
# Prepare data
# Compute monthly CES change and absolute revisions
### Task 4.5 ‚Äì Are revisions larger when the underlying CES change is larger?
#| label: ces-corr-change-revision
#| message: false
#| warning: false

library(dplyr)
library(stringr)

# 1. Prepare data: monthly CES change and absolute revision size
ces_corr <- ces |>
  arrange(date) |>
  mutate(
    ces_change    = level - lag(level), # month-over-month change
    abs_revision  = abs(revision) # absolute size of revision
  ) |>
  tidyr::drop_na(ces_change, abs_revision) # drop first row (no lag)

# 2. Pearson correlation test
cor_test_results <- cor.test(
  ces_corr$ces_change,
  ces_corr$abs_revision,
  method = "pearson"
)

# 3. Tidy summary table
cor_summary <- tibble::tibble(
  `Correlation (r)` = unname(cor_test_results$estimate),
  `t-Statistic`     = unname(cor_test_results$statistic),
  df                = unname(cor_test_results$parameter),
  `p-value`         = cor_test_results$p.value,
  `Lower 95% CI`    = cor_test_results$conf.int[1],
  `Upper 95% CI`    = cor_test_results$conf.int[2]
) |>
  # Round numeric columns
  mutate(
    across(where(is.numeric), ~ round(.x, 3)),
    Sig = dplyr::case_when(
      `p-value` < 0.001 ~ "***",
      `p-value` < 0.01 ~ "**",
      `p-value` < 0.05 ~ "*",
      TRUE ~ ""
    )
  )

# 4. Display nicely
nice_table(
  cor_summary,
  caption = "Correlation Between Monthly CES Level Change and Absolute Revision Size",
  page_len = 5
)
```
The correlation between monthly CES employment change and the absolute size of CES revisions is negative and statistically significant (r = ‚àí0.143, p < 0.01).This indicates that months with larger employment changes tend to have slightly smaller revisions, though the relationship is weak in magnitude (|r| ‚âà 0.14).

## Fact-Check BLS Revisions

### Fact-Check #1  
*‚ÄúThe BLS always underestimates job growth and then revises the numbers upward.‚Äù*

This claim appears frequently in media discussions. It implies that BLS initial
estimates are **systematically too low**, so revisions should usually be **positive**. With our
full CES dataset of total nonfarm payroll and revisions (1979‚Äì2025), we can test this directly.

#### Hypothesis Test

::: callout-note
**Question:** Is the *average* revision (final ‚àí original) strictly greater than zero?

We test the population mean revision:

$$
\begin{aligned}
H_0 &: \mu_{\text{revision}} = 0 \\
H_A &: \mu_{\text{revision}} > 0
\end{aligned}
$$

We use a **one-sample t-test** (Task 4.3), supplemented by a **bootstrap confidence interval**.
:::

#### Results

::: callout-important
**Summary of test statistics (Task 4.3)**

- **Observed mean revision:** \( \approx +11.50 \) thousand jobs  
- **95% bootstrap CI for mean:** \([ -6.85,\ +6.88 ]\) thousand  
- **t-statistic:** 3.26  
- **p-value:** 0.001 (formally ‚Äúsignificant‚Äù)  
:::

#### Interpretation

::: callout-result
Even though the point estimate of the mean revision is **slightly positive**, the **confidence
interval includes zero**, indicating that revisions vary widely from month to month. We do **not**
see strong evidence of a persistent upward bias in the level of revisions.
:::

#### Supporting Evidence (Tasks 2‚Äì3)

- **Mean revision:** about **+11.5k**  
- **Median revision:** roughly **+4k** (many small revisions in both directions)  
- **Fraction of positive revisions:** about **52.8%** ‚Äî only slightly above 50%  
- **Largest upward revision:** **+345k** (pandemic shock; clearly not a routine bias)  
- **Largest downward revision:** **‚àí537k** (also related to the pandemic era)  
- Time-series plots show revisions **jumping above and below zero** with no long-run trend.
- Decade-by-decade distributions have **medians near zero**, not consistently above zero.

::: callout-warning
**Bottom line:** The claim that *‚ÄúBLS always underestimates job growth and then revises up‚Äù* is **not supported** by the data. Revisions are noisy, not consistently positive, and no decade shows a clear
systematic upward bias.
:::

::: callout-tip
**PolitiFact-style rating:** üüß **Mostly False**
:::


---

### Fact-Check #2  
*‚ÄúBLS job numbers are manipulated during election years‚Äù*

This narrative resurfaces every four years. To evaluate it, we compare the **size** of revisions
in **presidential election years** versus **non-election years**.

Presidential election years since 1979 are:  
1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020, 2024.

We classify each month as:

- `election_year = TRUE` if it occurs in one of the election calendar years above  
- `election_year = FALSE` otherwise

#### Hypothesis Test

Because alleged *manipulation* would imply **larger** revisions, we compare **absolute** revision
magnitudes (size, regardless of sign).

::: callout-note
**Question:** Are absolute revisions larger in election years?

We test:

$$
\begin{aligned}
H_0 &: \mu_{\text{abs rev, election}} = \mu_{\text{abs rev, nonelection}} \\
H_A &: \mu_{\text{abs rev, election}} > \mu_{\text{abs rev, nonelection}}
\end{aligned}
$$

This is a **one-sided test** of whether volatility is higher during election years.
:::

#### Results (from Task 4.5)

::: callout-important
- **Mean absolute revision, election years:** ~55.2k  
- **Mean absolute revision, non-election years:** ~53.6k  
- **Difference (election ‚àí non-election):** +1.6k (very small)  
- **95% bootstrap CI for difference:** [‚àí18.5k, +21.0k]
:::

#### Interpretation

::: callout-result
The confidence interval again **spans zero**, so we find **no evidence** that revisions are
systematically larger in election years. Whatever differences exist are small relative to the
overall month-to-month variability in the series.
:::

#### Supporting Evidence

- **Mean revision (election years):** about **+8.7k**  
- **Mean revision (non-election years):** about **+11.9k**  
  - Non-election years actually have **slightly higher** mean revisions.  
- **Median absolute revisions** are **nearly identical** for election and non-election years.  
- The **largest swings** in the time-series occur around **recessions and COVID-19**, not during
typical election years.  
- Decade-by-decade plots show **no special election-year patterns**.

::: callout-warning
**Bottom line:** There is **no statistical evidence** that BLS revisions are larger, more positive,
or more negative in presidential election years. Any differences are small and are overshadowed by
macroeconomic shocks such as the recessions and the COVID-19 pandemic.
:::

::: callout-tip
**PolitiFact-style rating:** üî¥ **False**
:::

## Conclusion

Exploratory analysis showed steady long-term growth in U.S. employment, sharp declines during recessions, and occasional large revisions concentrated around the major economic shocks. Most revisions were small relative to total employment, though some months and decades consistently showed larger variability.

Statistical tests found no significant increase in negative revisions after 2000, no evidence that extremely large revisions became more common after 2020, and no statistically meaningful difference in average revision size before versus after the COVID-19 period. Overall, the data do not support claims that CES systematically underestimates job growth.

Finally, applying these results to real political claims showed that popular narratives about CES bias or partisan influence are not supported by empirical evidence. While revisions are unavoidable in a large, complex survey like the CES, they do not display long-term directional or political patterns.

------------------------------------------------------------------------

This work ¬©2025 by Actudata77 was initially prepared as a Mini-Project for
STA 9750 at Baruch College. More details about this course can be found at
[the course site](https://michael-weylandt.com/STA9750) and instructions for
this assignment can be found at 
[MP #04](https://michael-weylandt.com/STA9750/miniprojects/mini04.html)
